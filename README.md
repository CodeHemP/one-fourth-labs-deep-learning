# padh.ai - Deep Learning
Code and Documents related to Deep Learning Course at padh.ai

- ![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical`
- ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory`
- ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`
- ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`

| Module | Theory/Practical | Status | 
| ------ | ---------------- | ------ |
| 1. [Python Basics](/Module%2001%20-%20Python%20Basics) | ![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical`| ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete` | 
| 2. [6Jars and Expert Systems](/Module%2002%20-%206jars%20and%20Expert%20Systems) |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete` | 
| 3. [Linear Algebra Basics](/Module%2003%20-%20Vectors%20and%20Matrices)|![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 4. [Python Basics 2](/Module%2004%20-%20Python%20Basics2%20and%20Vectors) | ![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 5. [MP Neuron](/Module%2005%20-%20MCP) |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete` |
| 6. [Perceptron Model](/Module%2006%20-%20Perceptron) |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 7. [MP Neuron and Perceptron Practical](/Module%2007%20-%20MCP%20and%20Perceptron%20Code) |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete` |
| 8. [Sigmoid Neuron](/Module%2008%20-%20Sigmoid%20Neuron) |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 9. [Contest 1](/Module%2009%20-%20Contest1) |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 10. [Sigmoid Neuron using Python](/Module%2010%20-%20Python%20Sigmoid) |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete` |
| 11. [Probability]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 12. [Information Theory & Cross Entropy]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 13. [Contest 2]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 14. [Representation Power of Function]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 15. [Deep Neural Networks]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`| 
| 16. [DNNs using Python]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 17. [Backpropagation]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 18. [Backpropagation using Python]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 19. [Backpropagation 2]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`| 
| 20. [Backpropagating - the full version using Python]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 21. [Optimisation Algorithms Theory 1]() | ![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory`| ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 22. [Optimisation Algorithms Theory 2]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 23. [Optimisation Algorithms Practical]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 24. [Activation Functions & Initialisation Methods Theory]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 25. [Activation Functions & Initialisation Methods Practical]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 26. [Regularization Theory]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 27. [Regularization Practical]() | ![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical`| ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 28. [Basics of Pytorch]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` |  ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 29. [FNNs using Pytorch]() | ![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical`| ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 30. [The Convolution Operation]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 31. [Convolution to Neural Networks]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 32. [CNNs in Pytorch]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 33. [CNN Architectures 1]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 34. [CNN Architectures 2]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 35. [Building CNNs]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 36. [Visualising CNNs]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 37. [Batch Normalization and Dropout]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 38. [Batch Normalization and Dropout using Python]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 39. [Hypermeter Tuning and MLFlow]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 40. [Sequence Learning Problems]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete` |
| 41. [Recurrent Neural Networks]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 42. [Vanishing and Exploding Gradients]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 43. [LSTMs and GRUs]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 44. [Sequence Models in Pytorch]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 45. [Addressing the problem of vanishing and exploding gradients]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`| 
| 46. [Batching for Sequence Models in Pytorch]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 47. [Neural Encoders and Decoders]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 48. [Attention Mechanism]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#c5f015](https://placehold.it/15/c5f015/000000?text=+) `Complete`|
| 49. [Encoder Decoder Models and Attention Mechanism using PyTorch]() |![#ecf00a](https://placehold.it/15/ecf00a/000000?text=+) `Practical` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 50. [RCNN]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|
| 51. [YOLO]() |![#1589F0](https://placehold.it/15/1589F0/000000?text=+) `Theory` | ![#f03c15](https://placehold.it/15/f03c15/000000?text=+) `Incomplete`|

## Additional Readings for better understanding:

|Topic| Source | 
|---- | ---- |
|LSTMs solving vanishing gradient problem |[Link](https://weberna.github.io/blog/2017/11/15/LSTM-Vanishing-Gradients.html#fnref:2 )|
|Using nn.init methods for initialising weights in Pytorch|[Link](https://stackoverflow.com/questions/49433936/how-to-initialize-weights-in-pytorch)|
|Long Short-Term Memory: From Zero to Hero with PyTorch |[Link](https://blog.floydhub.com/long-short-term-memory-from-zero-to-hero-with-pytorch/)|
|Understanding the return type of nn.LSTM in Pytorch| [Link](https://discuss.pytorch.org/t/understanding-output-of-lstm/12320) | 
|Operating with variable length sequences for batching using packing in Pytorch | [Link](https://www.kdnuggets.com/2018/06/taming-lstms-variable-sized-mini-batches-pytorch.html)|
|Stackoverflow packing sequences| [Link](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch) |
|Backpropogation in CNN|[Link 1](https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/) , [Link 2](https://bit.ly/3eTkIfX)|
